function url_exists(){
local url="$1"
if curl -s --head "$url" | head -n 1 | grep -q "HTTP/1.1 404"; then
  return 1 #url returns 404
else
  return 0 #url exists
fi
}

name: CI

# Controls when the workflow will run
on:
  schedule:
    # * is a special character in YAML so you have to quote this string
    - cron:  '0 0 * * 0'



  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3
        
      - name: Environment Variables from Dotenv
        uses: c-py/action-dotenv-to-setenv@v4
      
      - name: Install required NCBI packages
        run: |
          #retrieve packages and set permissions
          curl -O 'https://ftp.ncbi.nlm.nih.gov/pub/datasets/command-line/v2/linux-amd64/dataformat'
          curl -O 'https://ftp.ncbi.nlm.nih.gov/pub/datasets/command-line/v2/linux-amd64/datasets'
          chmod +x datasets dataformat
          
      - name: Run query and get new rows
        run: |
          existing_assemblies="${{env.MATRIX_PATH}}"
          new_assemblies="output.tsv"
          ncbi_assemblies="ncbi.tsv"
          column_name="${{env.COLUMN_NAME}}"

          # Get TSV from dataset
          ./datasets summary genome accession ${{env.PROJECT_ACCESSION}} ${{env.DATASET_EXTRA_ARGS}} | ./dataformat tsv genome --fields ${{env.TSV_FIELDS}} >> "$ncbi_assemblies"
          
          if [ ! -s "$existing_assemblies" ]; then

            cat "$ncbi_assemblies" >> "$new_assemblies"
            awk -F'\t' -v OFS='\t' 'NR>1{new_value=$1; $(NF+1)="https://www.ebi.ac.uk/ena/browser/api/fasta/" new_value "?download=true"} 1' "$new_assemblies" >> "$existing_assemblies"
            sed -i "1s/$/\t$column_name/" "$existing_assemblies"

          else

            awk -F'\t' 'NR==FNR{a[$1];next} !($1 in a)' "$existing_assemblies" "$ncbi_assemblies" >> "$new_assemblies"
           
            awk -F'\t' -v OFS='\t' '{new_value=$1; $(NF+1)="https://www.ebi.ac.uk/ena/browser/api/fasta/" new_value "?download=true"} 1' "$new_assemblies" | while
            read accession acc_name organism url_download
            do
              check_exists=$(url_exists "$url_download")
              if [[ "$check_exists" -eq 0  ]]; then 
              	echo -e "$accession\t$acc_name\t$organism\t$url_download\n" >> "$existing_assemblies"
              fi
            done
            
          fi

          # Count new rows and set the environment variable
          new_rows=$(wc -l < "$new_assemblies")
          echo "new_rows=$new_rows" >> "$GITHUB_ENV"

          rm $new_assemblies
          rm $ncbi_assemblies
          
      - name: Commit & Push changes
        uses: actions-js/push@master
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          message: "Added ${{ env.new_rows }} new row(s)"
